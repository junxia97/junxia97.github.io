<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content=‚Äúwidth=800‚Äù>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
 
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    strongsmall {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
    }

    smalll {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
    }

    stronghuge {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700
    }

    huge {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 30px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="sjtu_icon.png">
  <title>Qingyun Sun</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link rel="shortcut icon" href="image/favicon.ico" />
  <link rel="bookmark" href="image/favicon.ico" />
  <meta name="google-site-verification" content="3Pi5gRNVZ_uFXQ1gBBx91DHgGFC32ASIPVvSeEiTqz8" />
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Jun Xia &nbsp;&nbsp;<font face="KaiTi" size="6">Â§è‰øä</font>
                </name>
              </p>
              <p>I‚Äôm a third-year PhD student at School of Computer Science and Engineering, <a href="https://ev.buaa.edu.cn/">Beihang University (BUAA)</a>, supervised by Prof. <a href="https://scholar.google.com/citations?user=EY2lqD0AAAAJ&hl=zh-CN">Jianxin Li</a>.
                I earned my Bachelor degree from <a href="https://en.xidian.edu.cn/">Xidian University</a>.
<!--              </p>-->
<!--                I was a research intern at <a href="https://www.yitutech.com/en">YITU Tech</a> working with <a href="https://cypw.github.io/">Yunpeng Chen</a> and <a href="https://scholar.google.com/citations?user=DNuiPHwAAAAJ&hl=zh-CN">Shuicheng Yan</a>.-->
<!--              <p>-->
                My research interests include Data Mining, Deep Graph Learning and Trustworthy AI.
              </p>
                <p align=center>
                  <a href="mailto:sunqy@act.buaa.edu.cn">Email: sunqy [at] act.buaa.cn</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=e2oYBzUAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                  <a href="https://github.com/SunQingYun1996">Github</a>

                </p>

            </td>
            <td width="16%">
              <img src="images/sunqy.jpg" width="130">
            </td>
          </tr>
        </table>


        <p></p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>News</heading>
              <div style="line-height:25px">
                <p>
                  <li>
                    <em>(2022.01)</em> <strong>One</strong> paper is accepted in <strong>WWW 2022</strong>. üòÑ
                  <li>
                    <em>(2021.11)</em> <strong>One</strong> paper is accepted in <strong>AAAI 2022</strong>. üòÑ
                  <li>
                    <em>(2021.10)</em> One IEEE ICDM 2021 paper was selected as <strong><font color="#a82e2e">Best Paper Candidate</font></strong>. üèÜ
                  <li>
                    <em>(2021.08)</em> <strong>One</strong> paper is accepted in <strong>ICDM 2020</strong>. üòÑ
                  <li>
                    <em>(2021.07)</em> We won the <strong><font color="#a82e2e">first prize</font></strong> at the 7th China "Internet+" Innovation and Entrepreneurship Competition (Beijing). üèÜ
                 <li>
                    <em>(2021.05)</em> Invited as a reviewer for IEEE TNNLS.
                  <li>
                    <em>(2021.04)</em> Invited as a reviewer for IEEE TKDE.
                  <li>
                    <em>(2021.03)</em> IInvited as a reviewer for KDD 2021.
                  <li>
                    <em>(2021.03)</em> Awarded the Student Scholarship Award of The Web Conference 2021. üèÜ
                  <li>
                    <em>(2021.01)</em> <strong>One</strong> paper is accepted in <strong>WWW 2021</strong>. üòÑ
                  <li>
                    <em>(2020.08)</em> <strong>One</strong> paper is accepted in <strong>ICDM 2020</strong>. üòÑ
                </p>
              </div>
            </td>
          </tr>
        </table>

        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/VIB-GSL.PNG' width="250" height="100">
            </td>
            <td valign="top" width="75%">
              <strong>Graph Structure Learning with Variational Information Bottleneck</strong>

              <br><br>
              <strong><u>Qingyun Sun</u></strong>,
              <a href="https://scholar.google.com/citations?user=EY2lqD0AAAAJ&hl=zh-CN&oi=ao">Jianxin Li</a>,
              <a href="https://penghao-bdsc.github.io/">Hao Peng</a>,
              <a href="http://web.science.mq.edu.au/~jiawu/">Jia Wu</a>,
              <a href="https://scholar.google.com/citations?user=gN4tbgMAAAAJ&hl=zh-CN">Xingcheng Fu</a>,
              <a href="https://scholar.google.com/citations?user=fRAeIZAAAAAJ&hl=zh-CN">Cheng Ji</a>,
              <a href="https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=zh-CN&oi=ao">Philip S. Yu</a>
              <br>

              <em>
                37th AAAI Conference on Artificial Intelligence. <strong>AAAI 2022</strong>.
                <br>
              </em>
                <!-- <br> -->
                <!-- , <a
                  href="https://github.com/Wangt-CN/MTFN-RR-PyTorch-Code"><strong>[Code]</strong></a> -->
                 <br>
                <a href="https://arxiv.org/pdf/2112.08903.pdf"><strong>[Paper]</strong></a>
              <p></p>

              <!-- <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable
                matching performance with acceptable model complexity and much less time consuming.
              </p> -->
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/SUGAR.PNG' width="250" height="100">
            </td>
            <td valign="top" width="75%">
              <strong>SUGAR: Subgraph Neural Network with Reinforcement Pooling and Self-Supervised Mutual Information Mechanism</strong>
              
              <br><br>
              <strong><u>Qingyun Sun</u></strong>,
              <a href="https://scholar.google.com/citations?user=EY2lqD0AAAAJ&hl=zh-CN&oi=ao">Jianxin Li</a>,
              <a href="https://penghao-bdsc.github.io/">Hao Peng</a>,
              <a href="http://web.science.mq.edu.au/~jiawu/">Jia Wu</a>,
              Yuanxing Ning,
              <a href="https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=zh-CN&oi=ao">Philip S. Yu</a>,
              <a href="https://scholar.google.com/citations?user=obgTcyoAAAAJ&hl=zh-CN&oi=ao">Lifang He</a>
              <br>
 
              <em>
                The Web Conference. <strong>WWW 2021</strong>.
                <br>
              </em>
                <!-- <br> -->
                <!-- , <a
                  href="https://github.com/Wangt-CN/MTFN-RR-PyTorch-Code"><strong>[Code]</strong></a> -->
                <a href="https://dl.acm.org/doi/pdf/10.1145/3442381.3449822"><strong>[Paper]</strong></a>
                <a href="https://github.com/RingBDStack/SUGAR"><strong>[Code]</strong></a>
              <p></p>
              <!-- <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable
                matching performance with acceptable model complexity and much less time consuming.
              </p> -->
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/ICDM20.PNG' width="250" height="100">
            </td>
            <td valign="top" width="75%">
              <strong>Pairwise Learning for Name Disambiguation in Large-Scale Heterogeneous Academic Networks</strong>
              
              <br><br>
              <strong><u>Qingyun Sun</u></strong>,
              <a href="https://penghao-bdsc.github.io/">Hao Peng</a>,
              <a href="https://scholar.google.com/citations?user=EY2lqD0AAAAJ&hl=zh-CN&oi=ao">Jianxin Li</a>,
              <a href="https://scholar.google.com/citations?user=zdWyGRMAAAAJ&hl=zh-CN&oi=ao">Senzhang Wang</a>,
              Xiangyu Dong,
              Liangxuan Zhao,
              <a href="https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=zh-CN&oi=ao">Philip S. Yu</a>,
              <a href="https://scholar.google.com/citations?user=obgTcyoAAAAJ&hl=zh-CN&oi=ao">Lifang He</a>
              <br>
 
              <em>
                20th IEEE International Conference on Data Mining. <strong>ICDM 2020</strong>.
                <br>
              </em>
                <!-- <br> -->
                <!-- , <a
                  href="https://github.com/Wangt-CN/MTFN-RR-PyTorch-Code"><strong>[Code]</strong></a> -->
                <a href="https://arxiv.org/pdf/2008.13099.pdf"><strong>[Paper]</strong></a>

              <p></p>
              <!-- <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable
                matching performance with acceptable model complexity and much less time consuming.
              </p> -->
            </td>
          </tr>
        </table>
        
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/ACE-GNN.PNG' width="250" height="120">
            </td>
            <td valign="top" width="75%">
              <strong>ACE-HGNN: Adaptive Curvature Exploration Hyperbolic Graph Neural Network</strong>
              <br><br>
              <a href="https://scholar.google.com/citations?user=gN4tbgMAAAAJ&hl=zh-CN">Xingcheng Fu</a>,
              <a href="https://scholar.google.com/citations?user=EY2lqD0AAAAJ&hl=zh-CN&oi=ao">Jianxin Li</a>,
              <a href="http://web.science.mq.edu.au/~jiawu/">Jia Wu</a>,
              <strong><u>Qingyun Sun</u></strong>,
              <a href="https://scholar.google.com/citations?user=fRAeIZAAAAAJ&hl=zh-CN">Cheng Ji</a>,
              <a href="https://scholar.google.com/citations?user=zdWyGRMAAAAJ&hl=zh-CN&oi=ao">Senzhang Wang</a>,
              Jiajun Tan,
              <a href="https://penghao-bdsc.github.io/">Hao Peng</a>,
              <a href="https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=zh-CN&oi=ao">Philip S. Yu</a>
              <br>
              <em>
                21th IEEE International Conference on Data Mining. <strong>ICDM 2021</strong>.
                <br>
              </em>
                <!-- <br> -->

                <em>
                <strong>
                  <font color="#a82e2e">(Best Paper Candidate)</font>
                </strong></em> <br>
                <a href="https://arxiv.org/pdf/2110.07888.pdf"><strong>[Paper]</strong></a>
                <a href=" https://github.com/RingBDStack/ACE-HGNN."><strong>[Code]</strong></a>
                  <br><br> 

              <p></p>
              <!-- <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable
                matching performance with acceptable model complexity and much less time consuming.
              </p> -->
            </td>
          </tr>
        </table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/AGE.PNG' width="250" height="115">
            </td>
            <td valign="top" width="75%">
              <strong>A Robust and Generalized Framework for Adversarial Graph Embedding</strong>
              
              <br><br>
              <a href="https://scholar.google.com/citations?user=EY2lqD0AAAAJ&hl=zh-CN&oi=ao">Jianxin Li</a>,
              <a href="https://scholar.google.com/citations?user=gN4tbgMAAAAJ&hl=zh-CN">Xingcheng Fu</a>,
              <a href="https://penghao-bdsc.github.io/">Hao Peng</a>,
              <a href="https://scholar.google.com/citations?user=zdWyGRMAAAAJ&hl=zh-CN&oi=ao">Senzhang Wang</a>,
              Shijie Zhu,
              <strong><u>Qingyun Sun</u></strong>,
              <a href="https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=zh-CN&oi=ao">Philip S. Yu</a>,
              <a href="https://scholar.google.com/citations?user=obgTcyoAAAAJ&hl=zh-CN&oi=ao">Lifang He</a>
              <br>
 
              <em>
                arXiv preprint arXiv:2105.10651, 2021
                <br>
              </em>
                <!-- <br> -->
                <a href="https://arxiv.org/abs/2105.10651"><strong>[Paper]</strong></a>
                <!-- , <a
                  href="https://github.com/Wangt-CN/MTFN-RR-PyTorch-Code"><strong>[Code]</strong></a> -->
                  
                  <br>

               <em>
                <!--<strong>
                  <font color="#a82e2e">(Oral Presentation, 4.96% acceptance rate)</font>
                </strong></em> <br> -->

              <!-- <em>Area: GANs</em> -->
              <br>
              <p></p>
              <!-- <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable
                matching performance with acceptable model complexity and much less time consuming.
              </p> -->
            </td>
          </tr>
        </table>

        <p></p>
        <p></p>
        <p></p>
        <p></p>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Academic Services</heading>
              <div style="line-height:25px">
                <br/>
                <strong>Program Committee:</strong>
                <ul>
                  <li> AAAI 2022
                </ul>
                <strong>Journal Reviewer:</strong>
                <ul>
                  <li>
                     IEEE Transactions on Knowledge and Data Engineering (TKDE).
                  <li>
                    IEEE Transactions on Neural Networks and Learning Systems (TNNLS).
                </ul>
                  <strong>Others</strong><br/>
                <ul>
                  <li> The Chairperson of <a href="https://www.ccf.org.cn/en/">CCF Beihang Student Branch</a>, 2021-Present.</li>
                </ul>
              </div>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Honors and Awards</heading>
              <div style="line-height:25px">
                <p>
                  <li>
                    The First Prize at the 7th China "Internet+" Innovation and Entrepreneurship Competition (Beijing), 2021.07<br />
                  <li>
                    Outstanding Academic Paper Award, Beihang University, 2021.04<br />
                  <li>
                    Student Scholarship Award of The Web Conference 2021, 2021.03<br />
                  <li>
                    National Scholarship, 2020.09<br />
                  <li>
                    Outstanding Freshman Scholarship, Beihang University, 2019.09<br />
                  <li>
                    Special Scholarship, Xidian University (Top 1%), 2017<br />
                </p>
              </div>
            </td>
          </tr>
        </table>


        <center>
          <a href="https://clustrmaps.com/site/1bmcr"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=xkIpHOAjn18cEy2DA8bdPBhIuzDEH3-rpKPaJAIdQXw&cl=ffffff" /></a>
        </center>
</body>

</html>
